{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'criterion': 'friedman_mse',\n",
       " 'init': None,\n",
       " 'learning_rate': 0.1,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 3,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_iter_no_change': None,\n",
       " 'presort': 'deprecated',\n",
       " 'random_state': 10,\n",
       " 'subsample': 1.0,\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 讀取葡萄酒資料集\n",
    "wine = datasets.load_wine()\n",
    "# 切分資料訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.25, random_state=42)\n",
    "# 建立模型\n",
    "clf = GradientBoostingClassifier(random_state=10)\n",
    "\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oriring accuracy: 0.911111 \n"
     ]
    }
   ],
   "source": [
    "# 觀察使用預設參數得到的結果\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Oriring accuracy: %f \" %acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LiaoChiFen\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 18 is smaller than n_iter=100. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    5.2s finished\n"
     ]
    }
   ],
   "source": [
    "# 設定要訓練的超參數組合\n",
    "\n",
    "# loss function to be optimized\n",
    "loss = ['deviance', 'exponential']\n",
    "# Maximum depth of the individual regression estimators\n",
    "max_depth = [3, 5, 7, 9]\n",
    "# The fraction of samples to be used for fitting the individual base learners\n",
    "subsample = [0.8, 0.9, 1]\n",
    "# The number of boosting stages to perform\n",
    "n_estimators = [50, 100, 150]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {\n",
    "    'loss': loss,\n",
    "    'subsample': subsample,\n",
    "    'n_estimators': n_estimators\n",
    "}\n",
    "\n",
    "# 建立搜尋物件\n",
    "## Random Search\n",
    "random_search = RandomizedSearchCV(clf, param_grid, n_iter = 100, verbose=2, random_state=42, n_jobs = -1)\n",
    "## Grid Search\n",
    "grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "\n",
    "## Random Search 搜尋參數\n",
    "random_result = random_search.fit(x_train, y_train)\n",
    "## Grid Search 搜尋最佳參數\n",
    "grid_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'n_estimators': 50, 'loss': 'deviance'}\n",
      "{'loss': 'deviance', 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Random Search\n",
    "print(random_result.best_params_)\n",
    "\n",
    "# Grid Search\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用隨機參數重新建立模型\n",
    "clf_bestparam_random = GradientBoostingClassifier(n_estimators=random_result.best_params_['n_estimators'],\n",
    "                                           subsample=random_result.best_params_['subsample'],\n",
    "                                           loss=random_result.best_params_['loss'])\n",
    "# 使用最佳參數重新建立模型\n",
    "clf_bestparam_grid = GradientBoostingClassifier(n_estimators=grid_result.best_params_['n_estimators'],\n",
    "                                           subsample=grid_result.best_params_['subsample'],\n",
    "                                           loss=grid_result.best_params_['loss'])\n",
    "# 訓練模型\n",
    "clf_bestparam_random.fit(x_train, y_train)\n",
    "clf_bestparam_grid.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred_random = clf_bestparam_random.predict(x_test)\n",
    "y_pred_grid = clf_bestparam_grid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Search accuracy: 0.911111 \n",
      "\n",
      "Grid Search accuracy: 0.911111 \n"
     ]
    }
   ],
   "source": [
    "# 觀察使用隨機參數得到的結果\n",
    "clf_bestparam_random.fit(x_train, y_train)\n",
    "y_pred_random = clf_bestparam_random.predict(x_test)\n",
    "acc_random = metrics.accuracy_score(y_test, y_pred)\n",
    "# 觀察使用最佳參數得到的結果\n",
    "clf_bestparam_grid.fit(x_train, y_train)\n",
    "y_pred_grid = clf_bestparam_grid.predict(x_test)\n",
    "acc_grid = metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Random Search accuracy: %f \" %acc)\n",
    "print(\"\\nGrid Search accuracy: %f \" %acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
